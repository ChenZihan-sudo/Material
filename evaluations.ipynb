{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/material/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from args import *\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from model import CEALNetwork, GCNNetwork, load_model\n",
    "\n",
    "import os.path as osp\n",
    "from train import make_data_loader, train_step, test_evaluations\n",
    "\n",
    "from module.madgap import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "train_dataset, validation_dataset, test_dataset = make_dataset()\n",
    "train_loader, val_loader, test_loader = make_data_loader(train_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "model, model_data = load_model(osp.join(args[\"result_path\"], \"CEAL/1717141328680483\"))\n",
    "model.eval()\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find features of high prediction error compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = MPDataset(args)\n",
    "print(all_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "def data_stat(data_list):\n",
    "    avg_num_edges = 0\n",
    "    avg_num_nodes = 0\n",
    "    for i,d in enumerate(data_list):\n",
    "        avg_num_edges+=d.edge_index.shape[-1]\n",
    "        avg_num_nodes+=d.x.shape[0]\n",
    "    total_graphs = i+1\n",
    "    return avg_num_nodes/total_graphs,avg_num_edges/total_graphs\n",
    "\n",
    "def ase_data_stat(ase_data_list):\n",
    "    avg_volume = 0.0\n",
    "    avg_radius = 0.0\n",
    "    \n",
    "    for i,d in enumerate(ase_data_list):\n",
    "        avg_volume+=d.get_volume()\n",
    "        \n",
    "        positions = d.get_positions()\n",
    "        dist_matrix = cdist(positions, positions)\n",
    "        max_distances = dist_matrix.max(axis=1)\n",
    "        radius = max_distances.max() / 2.0\n",
    "        avg_radius+=radius\n",
    "        \n",
    "    total = i+1\n",
    "    return avg_volume/total,avg_radius/total\n",
    "\n",
    "with torch.no_grad():\n",
    "    threshold = 0.5\n",
    "    high_pred_compounds = []\n",
    "    for i, batch_data in enumerate(test_loader):\n",
    "        batch_data.to(get_device())\n",
    "        out = model(batch_data, node_embedding=False)\n",
    "    \n",
    "        # reverse data scale\n",
    "        min, max = get_data_scale(args)\n",
    "        res_out = reverse_min_max_scalar_1d(out, min, max)\n",
    "        res_y =  reverse_min_max_scalar_1d( batch_data.y, min, max)\n",
    "        \n",
    "        # get high prediction error compounds\n",
    "        error =  (res_out.squeeze() - res_y).abs()\n",
    "        index = torch.where(error > threshold)[0]\n",
    "        compounds = [{'mid':data.mid,'idx':data.idx} for _,data in enumerate(batch_data[index])]\n",
    "        high_pred_compounds.extend(compounds)\n",
    "        \n",
    "        # high_pred_compounds.append()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    high_pred_compounds.sort(key=lambda x: int(x['idx']))\n",
    "    \n",
    "    \n",
    "    all_dataset = MPDataset(args)\n",
    "    dataset_stat = data_stat(all_dataset)\n",
    "    print(f\"dataset.             avg_num_nodes:{round(dataset_stat[0],4)}, avg_num_edges:{round(dataset_stat[1],4)}\")\n",
    "    # read all ase file from the whole dataset\n",
    "    whole_pred_ase = []\n",
    "    for i,d in enumerate(all_dataset):\n",
    "        path = osp.join(args[\"dataset_raw_dir\"],f\"CONFIG_{int(d.idx)}.poscar\")\n",
    "        compound = ase_read(path, format=\"vasp\")\n",
    "        whole_pred_ase.append(compound)\n",
    "    dataset_ase_stat = ase_data_stat(whole_pred_ase)\n",
    "    print(f\"dataset.               avg_volume:{round(dataset_ase_stat[0],4)}, avg_radius:{round(dataset_ase_stat[1],4)}\")\n",
    "\n",
    "    high_pred_data = [all_dataset[int(d['idx'])-1] for i,d in enumerate(high_pred_compounds)]\n",
    "    high_stat = data_stat(high_pred_data)\n",
    "    print(f\"high_pred_compounds. avg_num_nodes:{round(high_stat[0],4)}, avg_num_edges:{round(high_stat[1],4)}\")\n",
    "    # read all ase file from high pred error compounds\n",
    "    high_pred_ase = []\n",
    "    for i,d in enumerate(high_pred_data):\n",
    "        path = osp.join(args[\"dataset_raw_dir\"],f\"CONFIG_{int(d.idx)}.poscar\")\n",
    "        compound = ase_read(path, format=\"vasp\")\n",
    "        high_pred_ase.append(compound)\n",
    "    high_ase_stat = ase_data_stat(high_pred_ase)\n",
    "    print(f\"high_pred_compounds.  avg_volume:{round(high_ase_stat[0],4)}, avg_radius:{round(high_ase_stat[1],4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_total = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, batch_data in enumerate(train_loader):\n",
    "        batch_data.to(get_device())\n",
    "        node_embeddings = model(batch_data, node_embedding=True)\n",
    "\n",
    "        print(node_embeddings.shape)\n",
    "        \n",
    "        in_arr = node_embeddings.cpu().detach().numpy()\n",
    "\n",
    "        num_nodes = batch_data.x.shape[0]\n",
    "        adj = torch.zeros((num_nodes, num_nodes))\n",
    "        adj[batch_data.edge_index[0], batch_data.edge_index[1]] = 1\n",
    "        mask_arr = adj.numpy()\n",
    "\n",
    "        mad_single = mad_value(in_arr, mask_arr)\n",
    "        mad_total += mad_single\n",
    "        torch.cuda.empty_cache()\n",
    "        # print(i, \"single MAD:\", mad_single)\n",
    "\n",
    "print(\"MAD:\", mad_total / (i + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the reachable nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset.max_cutoff==3.5/processed\n"
     ]
    }
   ],
   "source": [
    "print(DATASET_PROCESSED_DIR)\n",
    "\n",
    "def reachable_nodes(num_nodes, edge_index, num_layers=1, ret_mat=False, device=get_device()):\n",
    "    adj = torch.tensor(np.eye(num_nodes), dtype=int).to(device)\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    if num_layers == 1:\n",
    "        return torch.sum(adj, dim=0).to(device) if ret_mat is False else adj\n",
    "\n",
    "    res_adj = adj\n",
    "\n",
    "    for i in range(0, num_layers - 1):\n",
    "        columns = []\n",
    "        for column in range(0, num_nodes):\n",
    "            # get column data\n",
    "            data = torch.where(res_adj[column] > 0)[0].to(device)\n",
    "            # get all node index data\n",
    "            data = torch.where(torch.sum(adj[data], dim=0) > 0)[0].to(device)\n",
    "\n",
    "            line = torch.zeros(num_nodes, dtype=int).to(device)\n",
    "            line[data] = 1\n",
    "            columns.append(line)\n",
    "        res_adj = torch.stack(columns).to(device)\n",
    "\n",
    "    return torch.sum(res_adj, dim=0).to(device) if ret_mat is False else res_adj\n",
    "\n",
    "\n",
    "def get_reachable_nodes(total_graphs, dataloader, num_layers, device=get_device()):\n",
    "    predict_epochs = math.ceil(total_graphs / args[\"batch_size\"])\n",
    "    pbar = tqdm(total=predict_epochs)\n",
    "    pbar.set_description(\"Progress\")\n",
    "\n",
    "    total_num_nodes = 0\n",
    "    total_reachable_nodes = 0\n",
    "\n",
    "    for i, batch_data in enumerate(dataloader):\n",
    "        num_nodes = batch_data.num_nodes\n",
    "        edge_index = batch_data.edge_index.to(device)\n",
    "\n",
    "        batch_reachable_nodes = torch.sum(reachable_nodes(num_nodes, edge_index, num_layers, ret_mat=False, device=device), dim=0)\n",
    "        total_reachable_nodes += batch_reachable_nodes\n",
    "\n",
    "        total_num_nodes += num_nodes\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    avg_reachable_nodes = (total_reachable_nodes / total_num_nodes).item()\n",
    "    avg_nodes_on_graph = total_num_nodes / total_graphs\n",
    "    print(f\"Layer {num_layers}\")\n",
    "    print(\"Average reachable nodes:\", avg_reachable_nodes)\n",
    "    print(\"Average nodes on a graph:\", avg_nodes_on_graph)\n",
    "    print(f\"=================================\")\n",
    "\n",
    "    return avg_reachable_nodes, avg_nodes_on_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 51/51 [08:26<00:00,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 3\n",
      "Average reachable nodes: 41.78022384643555\n",
      "Average nodes on a graph: 28.281324725011956\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(41.78022384643555, 28.281324725011956)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reachable_nodes(len(train_dataset), train_loader, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the shared reachable nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_shared_reachable_nodes(total_graphs, dataloader, num_layers, device=get_device()):\n",
    "\n",
    "total_graphs = len(train_dataset)\n",
    "dataloader = train_loader\n",
    "num_layers = 2\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "predict_epochs = math.ceil(total_graphs / args[\"batch_size\"])\n",
    "pbar = tqdm(total=predict_epochs)\n",
    "pbar.set_description(\"Progress\")\n",
    "\n",
    "total_num_nodes = 0\n",
    "total_reachable_nodes = 0\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data = train_dataset[1]\n",
    "    num_nodes = data.num_nodes\n",
    "    edge_index = data.edge_index.to(device)\n",
    "\n",
    "    batch_shared_reachable_nodes = reachable_nodes(num_nodes, edge_index, num_layers, ret_mat=False, device=device)\n",
    "    print(batch_shared_reachable_nodes)\n",
    "    # total_reachable_nodes += batch_shared_reachable_nodes\n",
    "\n",
    "    total_num_nodes += num_nodes\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    pbar.update(1)\n",
    "\n",
    "    # if i == 10:\n",
    "    break\n",
    "# pbar.close()\n",
    "\n",
    "# avg_reachable_nodes = (total_reachable_nodes / total_num_nodes).item()\n",
    "# avg_nodes_on_graph = total_num_nodes / total_graphs\n",
    "# print(f\"Layer {num_layers}\")\n",
    "# print(\"Average reachable nodes:\", avg_reachable_nodes)\n",
    "# print(\"Average nodes on a graph:\", avg_nodes_on_graph)\n",
    "# print(f\"=================================\")\n",
    "\n",
    "# return avg_reachable_nodes, avg_nodes_on_graph# def get_shared_reachable_nodes(total_graphs, dataloader, num_layers, device=get_device()):\n",
    "\n",
    "total_graphs = len(train_dataset)\n",
    "dataloader = train_loader\n",
    "num_layers = 2\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "predict_epochs = math.ceil(total_graphs / args[\"batch_size\"])\n",
    "pbar = tqdm(total=predict_epochs)\n",
    "pbar.set_description(\"Progress\")\n",
    "\n",
    "total_num_nodes = 0\n",
    "total_reachable_nodes = 0\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    data = train_dataset[1]\n",
    "    num_nodes = data.num_nodes\n",
    "    edge_index = data.edge_index.to(device)\n",
    "\n",
    "    batch_shared_reachable_nodes = reachable_nodes(num_nodes, edge_index, num_layers, ret_mat=False, device=device)\n",
    "    print(batch_shared_reachable_nodes)\n",
    "    # total_reachable_nodes += batch_shared_reachable_nodes\n",
    "\n",
    "    total_num_nodes += num_nodes\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    pbar.update(1)\n",
    "\n",
    "    # if i == 10:\n",
    "    break\n",
    "# pbar.close()\n",
    "\n",
    "# avg_reachable_nodes = (total_reachable_nodes / total_num_nodes).item()\n",
    "# avg_nodes_on_graph = total_num_nodes / total_graphs\n",
    "# print(f\"Layer {num_layers}\")\n",
    "# print(\"Average reachable nodes:\", avg_reachable_nodes)\n",
    "# print(\"Average nodes on a graph:\", avg_nodes_on_graph)\n",
    "# print(f\"=================================\")\n",
    "\n",
    "# return avg_reachable_nodes, avg_nodes_on_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reachability = torch.tensor(np.array([[1, 1, 0, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], dtype=bool))\n",
    "\n",
    "# 使用 np.all 检查每个节点在所有节点之间是否都可达\n",
    "overlapping_nodes = torch.all(reachability, axis=0)\n",
    "print(overlapping_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "material",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP_API_KEY = \"j61NN3yuDh8tQWf0OrkachbbUoJ8npVP\"\n",
    "\n",
    "CONVENTIONAL_UNIT_CELL = False\n",
    "\n",
    "WORK_DIR = \".\"\n",
    "\n",
    "DATASET_DIR = osp.join(\"{}\".format(WORK_DIR), \"dataset\")\n",
    "DATASET_RAW_DIR = osp.join(\"{}\".format(DATASET_DIR), \"raw\")\n",
    "DATASET_PROCESSED_DIR = osp.join(\"{}\".format(DATASET_DIR), \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset ./dataset/raw ./dataset/processed\n"
     ]
    }
   ],
   "source": [
    "print(DATASET_DIR, DATASET_RAW_DIR, DATASET_PROCESSED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b090c5335594120a6dc15207e4cb3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving SummaryDoc documents:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mp_api.client import MPRester\n",
    "\n",
    "# try:\n",
    "#     del material_id_data\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "mpr = MPRester(MP_API_KEY)\n",
    "\n",
    "# Get material id data with data filter\n",
    "mid_doc = mpr.materials.summary.search(\n",
    "    fields=[\"material_id\", \"formation_energy_per_atom\", \"structure\"],\n",
    "    exclude_elements=[\"O\"],\n",
    "    num_elements=(3, 3),\n",
    "    chunk_size=10,  # TODO: remove this if not debugging\n",
    "    num_chunks=1,  # TODO: remove this if not debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i, d in enumerate(mid_doc):\n",
    "    filename = osp.join(DATASET_RAW_DIR, \"CONFIG_\" + str(i + 1) + \".cif\")\n",
    "    output = d.structure.to_file(filename=filename, fmt=\"cif\")\n",
    "    indices.append(\n",
    "        {\n",
    "            \"idx\": i + 1,\n",
    "            \"mid\": str(d.material_id),\n",
    "            \"formation_energy_per_atom\": d.formation_energy_per_atom,\n",
    "        }\n",
    "    )\n",
    "indices_filename = osp.join(DATASET_RAW_DIR, \"INDICES\")\n",
    "with open(indices_filename, \"w\", newline=\"\") as f:\n",
    "    cw = csv.DictWriter(f, fieldnames=[\"idx\", \"mid\", \"formation_energy_per_atom\"])\n",
    "    cw.writeheader()\n",
    "    cw.writerows(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/processed'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MPDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        # self.args = args\n",
    "        # self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> list[str]:\n",
    "        return [\"data.pt\"]\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"INDICES\"]\n",
    "\n",
    "    def download(self):\n",
    "        print(\"download\")\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        print(\"process\")\n",
    "        pass\n",
    "\n",
    "    def len(self) -> int:\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        # data = torch.load(osp.join(self.processed_dir, f\"data_{idx}.pt\"))\n",
    "        return None\n",
    "\n",
    "\n",
    "dataset = MPDataset(root=\"./dataset\")\n",
    "dataset.processed_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: remove this if not debugging\n",
    "# mid_list = mid_list[0:100]\n",
    "\n",
    "# indices = []\n",
    "# structures = []\n",
    "\n",
    "# for i, d in enumerate(mid_list):\n",
    "#     print(\"Progress: {}/{}\".format(i + 1, len(mid_list)))\n",
    "#     st = mpr.get_structure_by_material_id(\n",
    "#         d, conventional_unit_cell=CONVENTIONAL_UNIT_CELL\n",
    "#     )\n",
    "#     structures.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = mpr.get_structure_by_material_id(\"mp-978908\", conventional_unit_cell=True)\n",
    "# print(st)\n",
    "# print(st.to_primitive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4133])\n",
      "(tensor([[0, 0, 1, 2, 2, 3],\n",
      "        [2, 3, 2, 0, 1, 0]]), tensor([3.2950, 3.2950, 3.2950, 3.2950, 3.2950, 3.2950]))\n",
      "tensor([[0, 0, 1, 2, 2, 3],\n",
      "        [2, 3, 2, 0, 1, 0]])\n",
      "tensor([3.2950, 3.2950, 3.2950, 3.2950, 3.2950, 3.2950])\n",
      "[['1', 'mp-861724', '-0.41328523750000556'], ['2', 'mp-1183076', '-0.4802780425000037'], ['3', 'mp-1183068', '-0.40283124874999743'], ['4', 'mp-1183063', '-0.46480851375000043'], ['5', 'mp-1183086', '-0.4336823506250056'], ['6', 'mp-862319', '-0.5426539487500008'], ['7', 'mp-862786', '-0.38625132874999935'], ['8', 'mp-861883', '-0.3422987462500018'], ['9', 'mp-1183120', '-0.01683831749999598'], ['10', 'mp-867122', '-0.2711647174999996']]\n",
      "tensor([[89, 89, 47, 77]])\n",
      "tensor([[89],\n",
      "        [89],\n",
      "        [47],\n",
      "        [77]])\n",
      "torch.Size([1, 6])\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ase.io import read as ase_read\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "indices_filename = osp.join(\"{}\".format(DATASET_RAW_DIR), \"INDICES\")\n",
    "assert osp.exists(indices_filename), \"INDICES file not exist in \" + indices_filename\n",
    "with open(indices_filename) as f:\n",
    "    reader = csv.reader(f)\n",
    "    indices = [row for row in reader][1:]\n",
    "# filenames = [\"CONFIG_\" + d[0] + \".cif\" for _, d in enumerate(indices)]\n",
    "# filenames.append(\"INDICES\")\n",
    "# for i, d in enumerate(indices):\n",
    "\n",
    "d = indices[0]\n",
    "idx, mid, y = d[0], d[1], d[2]\n",
    "filename = osp.join(\"{}\".format(DATASET_RAW_DIR), \"CONFIG_\" + idx + \".cif\")\n",
    "\n",
    "compound = ase_read(filename, format=\"cif\")\n",
    "\n",
    "# get distance matrix\n",
    "distance_matrix = compound.get_all_distances(mic=False)\n",
    "# get mask by max cutoff distance\n",
    "cutoff_mask = distance_matrix > 4.0\n",
    "# suppress invalid values using max cutoff distance\n",
    "distance_matrix = np.ma.array(distance_matrix, mask=cutoff_mask)\n",
    "# let '--' in the masked array to 0\n",
    "distance_matrix = np.nan_to_num(np.where(cutoff_mask, np.isnan(distance_matrix), distance_matrix))\n",
    "# make it as a tensor\n",
    "distance_matrix = torch.Tensor(distance_matrix)\n",
    "\n",
    "y = torch.Tensor(np.array([y], dtype=np.float64))\n",
    "print(y)\n",
    "# dense transform to sparse to get edge_index and edge_attr\n",
    "# data.y = torch.tensor()\n",
    "\n",
    "sparse_distance_matrix = dense_to_sparse(distance_matrix)\n",
    "print(sparse_distance_matrix)\n",
    "print(sparse_distance_matrix[0])\n",
    "print(sparse_distance_matrix[1])\n",
    "print(indices)\n",
    "\n",
    "print(torch.LongTensor(np.array([compound.get_atomic_numbers()])))\n",
    "print(torch.LongTensor(np.array([compound.get_atomic_numbers()])).t().contiguous())\n",
    "\n",
    "print(torch.Tensor(np.array([sparse_distance_matrix[1]], dtype=np.float32)).shape)\n",
    "print(torch.Tensor(np.array([sparse_distance_matrix[1]], dtype=np.float32)).t().contiguous().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True  True  True]\n",
      " [ True False  True  True]\n",
      " [ True  True False  True]\n",
      " [ True  True  True False]]\n",
      "[[False  True False False]\n",
      " [ True False  True False]\n",
      " [False  True False  True]\n",
      " [False False  True False]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(\n",
    "    [\n",
    "        [0.0, 7.04464783, 3.52232392, 10.56697175],\n",
    "        [7.04464783, 0.0, 3.52232392, 3.52232392],\n",
    "        [3.52232392, 3.52232392, 0.0, 7.04464783],\n",
    "        [10.56697175, 3.52232392, 7.04464783, 0.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "b = np.array(\n",
    "    [\n",
    "        [0.0, 5.86651732, 2.93325866, 2.93325866],\n",
    "        [5.86651732, 0.0, 8.79977597, 2.93325866],\n",
    "        [2.93325866, 8.79977597, 0.0, 5.86651732],\n",
    "        [2.93325866, 2.93325866, 5.86651732, 0.0],\n",
    "    ]\n",
    ")\n",
    "print(a > 3.0)\n",
    "print(b > 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "print(filenames.append([\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'phonopy'\n",
      "No module named 'phonopy'\n",
      "Downloading raw dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc71e61424a4406489315239a27ab570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving SummaryDoc documents:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Processing dataset: 100%|██████████| 100/100 [00:00<00:00, 1120.49it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from args import *\n",
    "from dataset import *\n",
    "\n",
    "dataset = MPDataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 6], edge_attr=[6, 1], x=[4, 1], y=[1])\n",
      "tensor([[0, 0, 1, 2, 2, 3],\n",
      "        [2, 3, 2, 0, 1, 0]])\n",
      "tensor([[3.2950],\n",
      "        [3.2950],\n",
      "        [3.2950],\n",
      "        [3.2950],\n",
      "        [3.2950],\n",
      "        [3.2950]])\n",
      "tensor([[89],\n",
      "        [89],\n",
      "        [47],\n",
      "        [77]])\n",
      "tensor([-0.4133])\n"
     ]
    }
   ],
   "source": [
    "d = dataset[0]\n",
    "print(d, d.edge_index, d.edge_attr, d.x, d.y, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([0, 1, 2, 3, 4, 5])\n",
    "print(torch.min(a).item())\n",
    "print(torch.max(a).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "from dataset import make_dataset\n",
    "from train import make_data_loader, train_step, test_evaluations\n",
    "from utils import get_device, plot_training_progress\n",
    "from model import GCNNetwork, CEALNetwork, save_model, load_model\n",
    "\n",
    "from args import *\n",
    "from utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output as ipyclear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset, test_dataset = make_dataset()\n",
    "train_loader, val_loader, test_loader = make_data_loader(train_dataset, validation_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CEAL\"\n",
    "model_network = model_name + \"Network\"\n",
    "model_args = args[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_data(\n",
    "    all_args,\n",
    "    epoch,\n",
    "    model,\n",
    "    train_losses,\n",
    "    val_losses,\n",
    "    test_losses,\n",
    "    test_loader,\n",
    "    test_dataset,\n",
    "    device,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    result_path,\n",
    "    regression_title=\"Model Regression\",\n",
    "    save_split=100,\n",
    "    training=False,\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    if epoch % save_split != 0 and training is True:\n",
    "        return\n",
    "\n",
    "    print(\"Saving data...\")\n",
    "    save_hyper_parameter(all_args, result_path)\n",
    "    save_train_progress(epoch - 1, train_losses, val_losses, test_losses, result_path)\n",
    "    test_loss, test_out, test_y = test_evaluations(model, test_loader, test_dataset, device, ret_data=True)\n",
    "\n",
    "    # Reverse normalization of test_out and y\n",
    "    min, max = get_data_scale(all_args)\n",
    "    test_y = reverse_min_max_scalar_1d(test_y, min, max)\n",
    "    test_out = reverse_min_max_scalar_1d(test_out, min, max)\n",
    "    loss = (test_out.squeeze() - test_y).abs().mean()\n",
    "    print(\"MAE loss: \", loss.item())\n",
    "\n",
    "    # save results\n",
    "    plot_training_progress(len(train_losses), train_losses, val_losses, test_losses, res_path=result_path,threshold=0.2)\n",
    "    save_regression_result(test_out, test_y, result_path)\n",
    "    plot_regression_result(regression_title, result_path, plotfilename=\"regression_figure.jpeg\")\n",
    "\n",
    "    # save model\n",
    "    print(\"Saving model...\")\n",
    "    save_model(result_path, model, epoch, loss, optimizer, scheduler)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset), len(validation_dataset), len(test_dataset))\n",
    "\n",
    "device = get_device()\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "in_dim = train_dataset[0].x.shape[-1]\n",
    "print(in_dim)\n",
    "deg = generate_deg(train_dataset).float()\n",
    "deg = deg.to(device)\n",
    "model = CEALNetwork(deg, in_dim)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model_args[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=model_args[\"sche_mode\"], factor=model_args[\"sche_factor\"], patience=model_args[\"sche_patience\"], min_lr=model_args[\"sche_min_lr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = create_result_folder(osp.join(\"./results\", model_name))\n",
    "test_best_loss = None\n",
    "epoch = None\n",
    "\n",
    "save_split = 100\n",
    "show_plot_split = 50\n",
    "\n",
    "with open(osp.join(result_path, \"model_info.txt\"), \"w\") as file:\n",
    "    print(model, file=file)\n",
    "    file.close()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "val_losses = []\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs. Epoch during Training\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 0 if epoch is None else epoch\n",
    "epoch = epoch_start - 1\n",
    "epochs = model_args[\"epochs\"]\n",
    "\n",
    "pbar = tqdm(total=(epochs + 1))\n",
    "pbar.update(epoch_start + 1)\n",
    "\n",
    "for epoch in range(epoch_start + 1, epochs + 1):\n",
    "\n",
    "    # auto save and evaluate at every 100 epoch step\n",
    "    save_result_data(\n",
    "        args,\n",
    "        epoch,\n",
    "        model,\n",
    "        train_losses,\n",
    "        val_losses,\n",
    "        test_losses,\n",
    "        test_loader,\n",
    "        test_dataset,\n",
    "        device,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        result_path,\n",
    "        regression_title=model_name,\n",
    "        save_split=save_split,\n",
    "        training=True,\n",
    "    )\n",
    "\n",
    "    model, train_loss = train_step(model, train_loader, train_dataset, optimizer, device)\n",
    "    torch.cuda.empty_cache()\n",
    "    val_loss, _, _ = test_evaluations(model, val_loader, validation_dataset, device, ret_data=False)\n",
    "    torch.cuda.empty_cache()\n",
    "    test_loss, _, _ = test_evaluations(model, test_loader, test_dataset, device, ret_data=False)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    plot_training_progress(len(train_losses), train_losses, val_losses, test_losses, split=show_plot_split,threshold=0.2)\n",
    "\n",
    "    # save best model\n",
    "    if test_best_loss is None or test_loss < test_best_loss:\n",
    "        test_best_loss = test_loss\n",
    "        # save_model_GCN(epoch, model, optimizer, scheduler, result_path)\n",
    "\n",
    "    progress_msg = (\n",
    "        \"epoch:\"\n",
    "        + str(epoch)\n",
    "        + \" train:\"\n",
    "        + str(round(train_loss, 4))\n",
    "        + \" valid:\"\n",
    "        + str(round(val_loss, 4))\n",
    "        + \" test:\"\n",
    "        + str(round(test_loss, 4))\n",
    "        + \" lr:\"\n",
    "        + str(round(current_lr, 8))\n",
    "        + \" best_test:\"\n",
    "        + str(round(test_best_loss, 4))\n",
    "    )\n",
    "    pbar.set_description(progress_msg)\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model, results and checkpoint if need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result_data(\n",
    "    args,\n",
    "    epoch,\n",
    "    model,\n",
    "    train_losses, \n",
    "    val_losses \n",
    "    test_losses,\n",
    "    test_loader,\n",
    "    test_dataset,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    result_path,\n",
    "    regression_title=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse data scale\n",
    "min, max = get_data_scale(args)\n",
    "\n",
    "test_loss, test_out, test_y = test_evaluations(model, test_loader, test_dataset, device, ret_data=True)\n",
    "test_out = reverse_min_max_scalar_1d(test_out, min, max)\n",
    "test_y = reverse_min_max_scalar_1d(test_y, min, max)\n",
    "loss = (test_out.squeeze() - test_y).abs().mean()\n",
    "print(loss)\n",
    "\n",
    "plt.hist(test_y.to(\"cpu\"), range=(-5, 5), bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# All Tune configurations can be inherited from the original config.yml.
# The original config.yml settings that overlap with the Tune configurations
# will be replaced by the Tune configurations.

# ===============Template===============
# value: # any value you want to tune in here
#   tune: [method, *params]
#
# Paramters
# tune   => tags for recognization
# method => search methods in tune or customed by the user
# params => search params
# ======================================

Process:
  max_cutoff_distance:
    tune: [choice, [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]]
    # tune: [choice, [1.0]]
  edge:
    edge_feature:
      tune: [choice, [20, 30, 40, 50, 60]]
      # tune: [choice, [20]]
    gaussian_smearing:
      width:
        tune: [choice, [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]]

Tuning:
  data_loader:
    batch_size:
      # tune: [choice, [100, 200, 300, 400, 500]] # [qrandint, 600, 800, 100]
      tune: [choice, [100, 130, 170, 200]] # [qrandint, 600, 800, 100]

Models:
  ChemGNN:
    conv_params:
      #   aggregators: [sum, mean, min, max, std]
      #   scalers: [identity]
      #   towers: 1
      #   pre_layers: 1
      #   post_layers: 1
      #   divide_input: false
      aggMLP:
        tune: [choice, [True, False]]
      aggMLP_factor:
        tune: [choice, [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]]
    pre_fc_dim:
      tune: [fc_dim, [0, 1, 2, 3, 4], [50, 75, 100, 125, 150, 175, 200]] # choice, num_layers and dim
    num_layers:
      tune: [choice, [1, 2, 3, 4]]
    conv_out_dim:
      tune: [choice, [50, 75, 100, 125, 150, 175, 200]]
    post_fc_dim:
      tune: [fc_dim, [0, 1, 2, 3, 4], [50, 75, 100, 125, 150, 175, 200]] # choice, num_layers and dim
    # dropout_rate:
    #   tune: [choice, [0.0, 0.1, 0.2, 0.3]]
    pool:
      tune: [choice, ["global_mean_pool", "global_max_pool", "global_add_pool"]]
    learning_rate:
      tune: [loguniform, 0.005, 0.05]
    # optimizer:
    #   name: AdamW
    #   params:
    scheduler:
      # name: ReduceLROnPlateau
      params:
        # mode: min
        factor:
          tune: [choice, [0.6, 0.7, 0.8, 0.9]]
        patience:
          tune: [choice, [10, 15, 20, 25, 30]]
        # min_lr: 0.00000001

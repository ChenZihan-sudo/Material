{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/catcolia/anaconda3/envs/material/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "from dataset import make_dataset\n",
    "from train import make_data_loader, train_step, test_evaluations, save_model_GCN\n",
    "from utils import get_device, plot_training_progress\n",
    "from model import GCNNetwork\n",
    "\n",
    "from args import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"GCN\"\n",
    "model_args = args[model_name]\n",
    "train_dataset, validation_dataset, test_dataset = make_dataset()\n",
    "train_loader, val_loader, test_loader = make_data_loader(train_dataset, validation_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23385, 100]) torch.Size([2, 217175]) torch.Size([217175])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data.x.shape, data.edge_index.shape, data.edge_weight.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29274 6273 6272\n",
      "torch.Size([14, 100])\n",
      "GCNNetwork(\n",
      "  (pre_fc): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (pre_fc_bns): ModuleList(\n",
      "    (0-1): 2 x BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(200, 100)\n",
      "    (1): GCNConv(100, 100)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0-1): 2 x BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (post_fc): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (post_fc_bns): ModuleList(\n",
      "    (0-1): 2 x BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (out_lin): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(validation_dataset), len(test_dataset))\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "in_dim = train_dataset[0].x.shape[-1]\n",
    "print(train_dataset[0].x.shape)\n",
    "\n",
    "model = GCNNetwork(in_dim)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model_args[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=model_args[\"sche_mode\"], factor=model_args[\"sche_factor\"], patience=model_args[\"sche_patience\"], min_lr=model_args[\"sche_min_lr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = create_result_folder(osp.join(\"./results\", model_name))\n",
    "test_best_loss = None\n",
    "epoch = None\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "val_losses = []\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs. Epoch during Training\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 0 if epoch is None else epoch\n",
    "epoch = epoch_start\n",
    "epochs = model_args[\"epochs\"]\n",
    "\n",
    "for epoch in range(epoch_start + 1, epochs + 1):\n",
    "\n",
    "    model, train_loss = train_step(model, train_loader, train_dataset, optimizer, device)\n",
    "    val_loss, _, _ = test_evaluations(model, val_loader, validation_dataset, device, ret_data=False)\n",
    "    test_loss, _, _ = test_evaluations(model, test_loader, test_dataset, device, ret_data=False)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    plot_training_progress(len(train_losses), train_losses, val_losses, test_losses, split=15)\n",
    "\n",
    "    # save best model\n",
    "    if test_best_loss is None or test_loss < test_best_loss:\n",
    "        test_best_loss = test_loss\n",
    "        save_model_GCN(epoch, model, optimizer, scheduler, result_path)\n",
    "\n",
    "    progress_msg = \"Epoch \" + str(epoch)\n",
    "    progress_msg += \", train loss(MAE)=\" + str(round(train_loss, 4))\n",
    "    progress_msg += \", valid loss(MAE)=\" + str(round(val_loss, 4))\n",
    "    progress_msg += \", test loss(MAE)=\" + str(round(test_loss, 4))\n",
    "    progress_msg += \", lr=\" + str(round(current_lr, 8))\n",
    "    progress_msg += \", best_test=\" + str(round(test_best_loss, 4))\n",
    "\n",
    "    print(progress_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(osp.join(result_path, \"checkpoint.pt\"), map_location=get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = checkpoint[\"model\"]\n",
    "\n",
    "save_hyper_parameter(args, result_path)\n",
    "save_train_progress(epoch - 1, train_losses, val_losses, test_losses, result_path)\n",
    "test_loss, test_out, test_y = test_evaluations(best_model, test_loader, test_dataset, device, ret_data=True)\n",
    "\n",
    "# Reverse normalization of test_out and y\n",
    "min, max = get_data_scale(args)\n",
    "test_y = reverse_min_max_scalar_1d(test_y, min, max)\n",
    "test_out = reverse_min_max_scalar_1d(test_out, min, max)\n",
    "loss = (test_out.squeeze() - test_y).abs().mean()\n",
    "print(\"MAE loss of formation energy is: \", loss.item())\n",
    "\n",
    "# save results\n",
    "plot_training_progress(len(train_losses), train_losses, val_losses, test_losses, res_path=result_path)\n",
    "save_regression_result(test_out, test_y, result_path)\n",
    "plot_regression_result(\"GCN\", result_path, plotfilename=\"regression_figure.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
